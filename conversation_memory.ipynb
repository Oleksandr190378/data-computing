{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjQOMQx3V5WNtkcki06CD2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oleksandr190378/data-computing/blob/main/conversation_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-openai langchain openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuLKVgLvvDPM",
        "outputId": "084cdb15-7c82-4386-cc16-be3ddf56ba8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain_community gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVLvVF6vLu5n",
        "outputId": "6ddf8e4c-aae5-48a8-d9d3-cfdd4a7f385a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import openai\n",
        "OPENAI_API_KEY = getpass.getpass(prompt='Введіть ваш OpenAI API ключ: ')\n",
        "\n",
        "print(\"API ключ успішно введений!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbKBo6a1vDEU",
        "outputId": "9994e194-3215-4d62-d3cd-e1c8750edd12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Введіть ваш OpenAI API ключ: ··········\n",
            "API ключ успішно введений!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "A5oqHWOVzAf-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        "    max_retries=2,\n",
        "    # api_key=\"...\",\n",
        "    # base_url=\"...\",\n",
        "    # organization=\"...\",\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "j8zNDnTG5FwX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmekWnxwK-To",
        "outputId": "1869c178-cba4-443d-ab0a-33cc7efb11b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7a41d89346a0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7a41d89367a0>, root_client=<openai.OpenAI object at 0x7a41fe928160>, root_async_client=<openai.AsyncOpenAI object at 0x7a41d8934700>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"вмієш розмовляти українською мовою? \"\n",
        "llm.invoke(input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6zAUkAV7SfZ",
        "outputId": "b89d07da-541a-4676-8483-36ff88b6231a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Так, я вмію розмовляти українською мовою. Як я можу вам допомогти?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 22, 'total_tokens': 47, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e9627b5346', 'finish_reason': 'stop', 'logprobs': None}, id='run-330586a1-fa94-4581-ae93-ee4a42ac5759-0', usage_metadata={'input_tokens': 22, 'output_tokens': 25, 'total_tokens': 47})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text= \"розкажи мені про нутриціологію\""
      ],
      "metadata": {
        "id": "-BmNKV68spJz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import HumanMessage\n",
        "response = llm.invoke([HumanMessage(content=input_text)])\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "xcw6APCXMj77",
        "outputId": "a4e4b4a8-e152-4aa6-b6fa-a1534a991cd4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Нутриціологія — це наука, що вивчає вплив харчування на здоров'я людини, розвиток, функціонування організму та профілактику захворювань. Вона охоплює різні аспекти, такі як біохімія, фізіологія, генетика, психологія та соціологія, щоб зрозуміти, як харчові речовини впливають на організм.\\n\\nОсновні аспекти нутриціології:\\n\\n1. **Харчові речовини**: Нутриціологія вивчає різні типи харчових речовин, такі як білки, жири, вуглеводи, вітаміни, мінерали та воду, а також їх роль у метаболізмі та загальному здоров'ї.\\n\\n2. **Дієта і здоров'я**: Нутриціологи аналізують, як різні дієти впливають на здоров'я, включаючи профілактику хронічних захворювань, таких як діабет, серцево-судинні захворювання та ожиріння.\\n\\n3. **Індивідуальні потреби**: Нутриціологія враховує індивідуальні потреби в харчуванні, які можуть змінюватися в залежності від віку, статі, фізичної активності, стану здоров'я та інших факторів.\\n\\n4. **Психологічні аспекти харчування**: Нутриціологи також досліджують, як емоції, стрес і соціальні фактори впливають на вибір їжі та харчові звички.\\n\\n5. **Дослідження і рекомендації**: Нутриціологи проводять дослідження, щоб розробити рекомендації щодо здорового харчування, які можуть бути використані для поліпшення загального стану здоров'я населення.\\n\\n6. **Клінічна нутриціологія**: Це спеціалізована галузь, яка займається лікуванням і профілактикою захворювань через корекцію харчування, часто в умовах лікарень або клінік.\\n\\nНутриціологія є важливою для розуміння того, як правильне харчування може покращити якість життя, підтримувати здоров'я та запобігати захворюванням.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "def count_tokens(chain, query):\n",
        "    with get_openai_callback() as cb:\n",
        "        result = chain.invoke(query)\n",
        "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
        "    return result"
      ],
      "metadata": {
        "id": "fSdU5qoxNCkV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jlh-ZCPry-l",
        "outputId": "cbaef5b1-f8dc-49c3-a180-45f14789cc7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-28d77252b1c7>:5: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  conversation_sum = ConversationChain(llm=llm, memory=memory,verbose=True)\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "memory = ConversationSummaryMemory(llm=llm)\n",
        "conversation_sum = ConversationChain(llm=llm, memory=memory,verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation_sum.memory.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FGKsU0fr2FI",
        "outputId": "c3a7506a-22c2-4db0-fb24-3656d701f94e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
            "\n",
            "EXAMPLE\n",
            "Current summary:\n",
            "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
            "\n",
            "New lines of conversation:\n",
            "Human: Why do you think artificial intelligence is a force for good?\n",
            "AI: Because artificial intelligence will help humans reach their full potential.\n",
            "\n",
            "New summary:\n",
            "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
            "END OF EXAMPLE\n",
            "\n",
            "Current summary:\n",
            "{summary}\n",
            "\n",
            "New lines of conversation:\n",
            "{new_lines}\n",
            "\n",
            "New summary:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = count_tokens(\n",
        "    conversation_sum,\n",
        "    \"good morning\"\n",
        ")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hld3mOlsC54",
        "outputId": "fa4f7401-4e29-4c84-af56-bbdec2a6feb6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: good morning\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 330 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'good morning',\n",
              " 'history': '',\n",
              " 'response': \"Good morning! How are you today? I hope you're having a great start to your day. Is there anything specific on your mind or something you'd like to chat about?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.conversation.memory import ConversationSummaryBufferMemory\n",
        "conversation_sumbuf = ConversationChain(llm=llm, memory=ConversationSummaryBufferMemory(llm=llm,max_token_limit=100),verbose=True)"
      ],
      "metadata": {
        "id": "H9e6iYN9s3Rf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation_sumbuf.memory.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvcXjN-atGGG",
        "outputId": "0662194f-c80d-47e1-8bb7-e9d8f35d232c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
            "\n",
            "EXAMPLE\n",
            "Current summary:\n",
            "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
            "\n",
            "New lines of conversation:\n",
            "Human: Why do you think artificial intelligence is a force for good?\n",
            "AI: Because artificial intelligence will help humans reach their full potential.\n",
            "\n",
            "New summary:\n",
            "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
            "END OF EXAMPLE\n",
            "\n",
            "Current summary:\n",
            "{summary}\n",
            "\n",
            "New lines of conversation:\n",
            "{new_lines}\n",
            "\n",
            "New summary:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens(\n",
        "    conversation_sumbuf,\n",
        "    \"hi good morning\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEbiAjpFtgqx",
        "outputId": "430653ca-2d16-41dd-9a42-09425e49e964"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: hi good morning\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 101 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'hi good morning',\n",
              " 'history': '',\n",
              " 'response': \"Good morning! How are you today? I hope you're having a great start to your day. Is there anything specific on your mind or something you'd like to chat about?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens(\n",
        "    conversation_sumbuf,\n",
        "    \"Please let me know how can I learn AI\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziPoB7F6tn-8",
        "outputId": "775a99ca-0313-4ab9-fcef-c0a50d3e4378"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: hi good morning\n",
            "AI: Good morning! How are you today? I hope you're having a great start to your day. Is there anything specific on your mind or something you'd like to chat about?\n",
            "Human: Please let me know how can I learn AI\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 1199 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Please let me know how can I learn AI',\n",
              " 'history': \"Human: hi good morning\\nAI: Good morning! How are you today? I hope you're having a great start to your day. Is there anything specific on your mind or something you'd like to chat about?\",\n",
              " 'response': \"Learning AI can be an exciting journey! Here are some steps you can take to get started:\\n\\n1. **Understand the Basics**: Begin with the foundational concepts of AI, including what it is, its history, and its various applications. You might want to read introductory books or articles on AI.\\n\\n2. **Mathematics and Statistics**: A solid understanding of mathematics, particularly linear algebra, calculus, and statistics, is crucial. These areas are fundamental to many AI algorithms.\\n\\n3. **Programming Skills**: Learn a programming language commonly used in AI, such as Python. Python has a rich ecosystem of libraries and frameworks like TensorFlow, PyTorch, and scikit-learn that are essential for AI development.\\n\\n4. **Online Courses**: There are many online platforms offering courses on AI and machine learning. Websites like Coursera, edX, and Udacity have courses from top universities and institutions. Look for courses that cover machine learning, deep learning, and data science.\\n\\n5. **Hands-On Projects**: Apply what you learn by working on projects. Start with simple projects, like building a basic chatbot or a recommendation system, and gradually take on more complex challenges.\\n\\n6. **Join Communities**: Engage with online communities, such as forums, social media groups, or local meetups. Websites like GitHub, Stack Overflow, and Reddit have active AI communities where you can ask questions and share your work.\\n\\n7. **Stay Updated**: AI is a rapidly evolving field. Follow AI research papers, blogs, and podcasts to keep up with the latest developments and trends.\\n\\n8. **Experiment and Iterate**: Don’t be afraid to experiment with different algorithms and techniques. Learning from your mistakes is a valuable part of the process.\\n\\nIf you have any specific areas of AI you're interested in, like natural language processing or computer vision, let me know, and I can provide more tailored resources!\"}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = count_tokens(\n",
        "    conversation_sumbuf,\n",
        "    \"which cloud  is best for AI\"\n",
        ")\n",
        "result['response']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "4FH_JfIPt0mz",
        "outputId": "fdfd8785-1966-4460-dfeb-3b045101c928"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "System: The human greets the AI with a \"good morning,\" and the AI responds warmly, asking how the human is doing and if there's anything specific they would like to discuss. The human inquires about how to learn AI, prompting the AI to outline several steps for getting started, including understanding the basics of AI, learning mathematics and statistics, acquiring programming skills (especially in Python), taking online courses, working on hands-on projects, joining AI communities, staying updated with the latest developments, and experimenting with different algorithms. The AI also offers to provide more tailored resources based on specific areas of interest in AI. The human then asks which cloud platform is best for AI, and the AI explains that the best choice depends on specific needs, detailing several popular options: Amazon Web Services (AWS) for scalability, Google Cloud Platform (GCP) for deep learning support, Microsoft Azure for integration with Microsoft products, IBM Cloud for natural language processing, and Oracle Cloud for data analytics. The AI emphasizes evaluating these platforms based on project requirements, budget, and familiarity, and offers to help narrow down options based on specific use cases.\n",
            "Human: which cloud  is best for AI\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 1501 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The best cloud platform for AI really depends on your specific needs and use cases. Here are some popular options:\\n\\n1. **Amazon Web Services (AWS)**: Known for its scalability and a wide range of AI services, AWS offers tools like SageMaker for building, training, and deploying machine learning models. It's a great choice if you need flexibility and a broad set of features.\\n\\n2. **Google Cloud Platform (GCP)**: GCP is particularly strong in deep learning and offers powerful tools like TensorFlow and AutoML. If you're focusing on advanced machine learning and AI research, GCP might be the best fit.\\n\\n3. **Microsoft Azure**: Azure integrates well with Microsoft products and provides a variety of AI services, including Azure Machine Learning. It's a solid choice if you're already using Microsoft tools in your organization.\\n\\n4. **IBM Cloud**: Known for its natural language processing capabilities, IBM Cloud offers Watson, which is great for building AI applications that require understanding and generating human language.\\n\\n5. **Oracle Cloud**: If your focus is on data analytics, Oracle Cloud provides robust tools for managing and analyzing large datasets, which can be beneficial for AI projects.\\n\\nWhen choosing a platform, consider factors like your project requirements, budget, and your team's familiarity with the platform. If you have a specific use case in mind, I can help you narrow down the options further!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_sumbuf.memory.buffer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "zD825jYet5fj",
        "outputId": "43520c67-46ad-4c35-ffad-fb93c95ae306"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'System: The human greets the AI with a \"good morning,\" and the AI responds warmly, asking how the human is doing and if there\\'s anything specific they would like to discuss. The human inquires about how to learn AI, prompting the AI to outline several steps for getting started, including understanding the basics of AI, learning mathematics and statistics, acquiring programming skills (especially in Python), taking online courses, working on hands-on projects, joining AI communities, staying updated with the latest developments, and experimenting with different algorithms. The AI also offers to provide more tailored resources based on specific areas of interest in AI. The human then asks which cloud platform is best for AI, and the AI explains that the best choice depends on specific needs, detailing several popular options: Amazon Web Services (AWS) for scalability, Google Cloud Platform (GCP) for deep learning support, Microsoft Azure for integration with Microsoft products, IBM Cloud for natural language processing, and Oracle Cloud for data analytics. The AI emphasizes evaluating these platforms based on project requirements, budget, and familiarity, and offers to help narrow down options based on specific use cases.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['response']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "LWsQuwmUQ9_9",
        "outputId": "9f16145a-7e68-4d34-b814-e8171e2dc2fe"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The best cloud platform for AI really depends on your specific needs and use cases. Here are some popular options:\\n\\n1. **Amazon Web Services (AWS)**: Known for its scalability and a wide range of AI services, AWS offers tools like SageMaker for building, training, and deploying machine learning models. It's a great choice if you need flexibility and a broad set of features.\\n\\n2. **Google Cloud Platform (GCP)**: GCP is particularly strong in deep learning and offers powerful tools like TensorFlow and AutoML. If you're focusing on advanced machine learning and AI research, GCP might be the best fit.\\n\\n3. **Microsoft Azure**: Azure integrates well with Microsoft products and provides a variety of AI services, including Azure Machine Learning. It's a solid choice if you're already using Microsoft tools in your organization.\\n\\n4. **IBM Cloud**: Known for its natural language processing capabilities, IBM Cloud offers Watson, which is great for building AI applications that require understanding and generating human language.\\n\\n5. **Oracle Cloud**: If your focus is on data analytics, Oracle Cloud provides robust tools for managing and analyzing large datasets, which can be beneficial for AI projects.\\n\\nWhen choosing a platform, consider factors like your project requirements, budget, and your team's familiarity with the platform. If you have a specific use case in mind, I can help you narrow down the options further!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "memory = ConversationSummaryBufferMemory(llm=llm,max_token_limit=100)\n",
        "\n",
        "def chat_with_rag(message):\n",
        "    conversation_sum = ConversationChain(llm=llm, memory=memory, verbose=True)\n",
        "    result = conversation_sum.invoke(message)\n",
        "\n",
        "    response_text = result['response']\n",
        "\n",
        "    pattern = r\"AI: ([\\s\\S]+?)(?=Human:|$)\"\n",
        "    matches = re.findall(pattern, response_text)\n",
        "\n",
        "    if matches:\n",
        "        last_ai_message = matches[-1].strip()\n",
        "        return last_ai_message\n",
        "    else:\n",
        "        return response_text"
      ],
      "metadata": {
        "id": "kLqWOr3j7UEu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "def gradio_chat(user_input):\n",
        "    bot_message = chat_with_rag(user_input)\n",
        "    return bot_message"
      ],
      "metadata": {
        "id": "R3J1kGK68J6g"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.Interface(\n",
        "    fn=gradio_chat,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Chat with AI\",\n",
        "    description=\"Chat with an AI assistant using OpenAI's GPT-4o-mini model.\"\n",
        ")"
      ],
      "metadata": {
        "id": "_8ZwTp3M8RgX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "T5Gnrg788WHG",
        "outputId": "6a183d02-ad90-4c06-ccf2-db940f71728a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://89722415ca405fc02d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://89722415ca405fc02d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}